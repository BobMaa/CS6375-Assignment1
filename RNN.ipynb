{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a315b20c-2f59-48f1-9508-992c6e20ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import string\n",
    "from argparse import ArgumentParser\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91f01c4f-7bd8-4b0b-8e35-0f68f35cf6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unk = '<UNK>'\n",
    "# Consult the PyTorch documentation for information on the functions used below:\n",
    "# https://pytorch.org/docs/stable/torch.html\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, h):  # Add relevant parameters\n",
    "        super(RNN, self).__init__()\n",
    "        self.h = h\n",
    "        self.numOfLayer = 1\n",
    "        self.rnn = nn.RNN(input_dim, h, self.numOfLayer, nonlinearity='tanh')\n",
    "        self.W = nn.Linear(h, 5)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.loss = nn.NLLLoss()\n",
    "\n",
    "    def compute_Loss(self, predicted_vector, gold_label):\n",
    "        return self.loss(predicted_vector, gold_label)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # [to fill] obtain hidden layer representation (https://pytorch.org/docs/stable/generated/torch.nn.RNN.html)\n",
    "        outputs, hidden = self.rnn(inputs)\n",
    "        # [to fill] obtain output layer representations\n",
    "        output_layer = self.W(outputs)\n",
    "        # [to fill] sum over output \n",
    "        sumed_outputs = torch.sum(output_layer, dim=0)\n",
    "        # [to fill] obtain probability dist.\n",
    "        predicted_vector = self.softmax(sumed_outputs)\n",
    "        return predicted_vector\n",
    "\n",
    "\n",
    "def load_data(train_data, val_data):\n",
    "    with open(train_data) as training_f:\n",
    "        training = json.load(training_f)\n",
    "    with open(val_data) as valid_f:\n",
    "        validation = json.load(valid_f)\n",
    "\n",
    "    tra = []\n",
    "    val = []\n",
    "    for elt in training:\n",
    "        tra.append((elt[\"text\"].split(),int(elt[\"stars\"]-1)))\n",
    "    for elt in validation:\n",
    "        val.append((elt[\"text\"].split(),int(elt[\"stars\"]-1)))\n",
    "    return tra, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a2f6ba2-bf33-447a-a6ce-65524bbcb6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Loading data ==========\n",
      "========== Vectorizing data ==========\n",
      "Training started for epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [04:14<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2633)\n",
      "Training completed for epoch 1\n",
      "Training accuracy for epoch 1: 0.2845625\n",
      "Validation started for epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 800/800 [00:05<00:00, 155.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation completed for epoch 1\n",
      "Validation accuracy for epoch 1: 0.16\n",
      "Training started for epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [04:22<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6419)\n",
      "Training completed for epoch 2\n",
      "Training accuracy for epoch 2: 0.3295\n",
      "Validation started for epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 800/800 [00:05<00:00, 155.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation completed for epoch 2\n",
      "Validation accuracy for epoch 2: 0.38125\n",
      "Training started for epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [04:22<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6288)\n",
      "Training completed for epoch 3\n",
      "Training accuracy for epoch 3: 0.342375\n",
      "Validation started for epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 800/800 [00:05<00:00, 157.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation completed for epoch 3\n",
      "Validation accuracy for epoch 3: 0.435\n",
      "Training started for epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [04:23<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6636)\n",
      "Training completed for epoch 4\n",
      "Training accuracy for epoch 4: 0.33775\n",
      "Validation started for epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 800/800 [00:05<00:00, 158.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation completed for epoch 4\n",
      "Validation accuracy for epoch 4: 0.3\n",
      "Training started for epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [04:23<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6510)\n",
      "Training completed for epoch 5\n",
      "Training accuracy for epoch 5: 0.338125\n",
      "Validation started for epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 800/800 [00:05<00:00, 157.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation completed for epoch 5\n",
      "Validation accuracy for epoch 5: 0.22875\n",
      "Training done to avoid overfitting!\n",
      "Best validation accuracy is: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = './Data_Embedding/training.json'\n",
    "valid_data = './Data_Embedding/validation.json'\n",
    "print(\"========== Loading data ==========\")\n",
    "train_data, valid_data = load_data(train_data, valid_data) # X_data is a list of pairs (document, y); y in {0,1,2,3,4}\n",
    "hidden_dim = 100\n",
    "# Think about the type of function that an RNN describes. To apply it, you will need to convert the text data into vector representations.\n",
    "# Further, think about where the vectors will come from. There are 3 reasonable choices:\n",
    "# 1) Randomly assign the input to vectors and learn better embeddings during training; see the PyTorch documentation for guidance\n",
    "# 2) Assign the input to vectors using pretrained word embeddings. We recommend any of {Word2Vec, GloVe, FastText}. Then, you do not train/update these embeddings.\n",
    "# 3) You do the same as 2) but you train (this is called fine-tuning) the pretrained embeddings further.\n",
    "# Option 3 will be the most time consuming, so we do not recommend starting with this\n",
    "\n",
    "print(\"========== Vectorizing data ==========\")\n",
    "model = RNN(50, hidden_dim)  # Fill in parameters\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "word_embedding = pickle.load(open('./Data_Embedding/word_embedding.pkl', 'rb'))\n",
    "\n",
    "stopping_condition = False\n",
    "epoch = 0\n",
    "\n",
    "last_train_accuracy = 0\n",
    "last_validation_accuracy = 0\n",
    "\n",
    "while not stopping_condition:\n",
    "    random.shuffle(train_data)\n",
    "    model.train()\n",
    "    # You will need further code to operationalize training, ffnn.py may be helpful\n",
    "    print(\"Training started for epoch {}\".format(epoch + 1))\n",
    "    train_data = train_data\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    minibatch_size = 16\n",
    "    N = len(train_data)\n",
    "\n",
    "    loss_total = 0\n",
    "    loss_count = 0\n",
    "    for minibatch_index in tqdm(range(N // minibatch_size)):\n",
    "        optimizer.zero_grad()\n",
    "        loss = None\n",
    "        for example_index in range(minibatch_size):\n",
    "            input_words, gold_label = train_data[minibatch_index * minibatch_size + example_index]\n",
    "            input_words = \" \".join(input_words)\n",
    "\n",
    "            # Remove punctuation\n",
    "            input_words = input_words.translate(input_words.maketrans(\"\", \"\", string.punctuation)).split()\n",
    "\n",
    "            # Look up word embedding dictionary\n",
    "            vectors = [word_embedding[i.lower()] if i.lower() in word_embedding.keys() else word_embedding['unk'] for i in input_words ]\n",
    "\n",
    "            # Transform the input into required shape\n",
    "            vectors = torch.tensor(vectors).view(len(vectors), 1, -1)\n",
    "            output = model(vectors)\n",
    "\n",
    "            # Get loss\n",
    "            example_loss = model.compute_Loss(output.view(1,-1), torch.tensor([gold_label]))\n",
    "\n",
    "            # Get predicted label\n",
    "            predicted_label = torch.argmax(output)\n",
    "\n",
    "            correct += int(predicted_label == gold_label)\n",
    "            # print(predicted_label, gold_label)\n",
    "            total += 1\n",
    "            if loss is None:\n",
    "                loss = example_loss\n",
    "            else:\n",
    "                loss += example_loss\n",
    "\n",
    "        loss = loss / minibatch_size\n",
    "        loss_total += loss.data\n",
    "        loss_count += 1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss_total/loss_count)\n",
    "    print(\"Training completed for epoch {}\".format(epoch + 1))\n",
    "    print(\"Training accuracy for epoch {}: {}\".format(epoch + 1, correct / total))\n",
    "    trainning_accuracy = correct/total\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    random.shuffle(valid_data)\n",
    "    print(\"Validation started for epoch {}\".format(epoch + 1))\n",
    "    valid_data = valid_data\n",
    "\n",
    "    for input_words, gold_label in tqdm(valid_data):\n",
    "        input_words = \" \".join(input_words)\n",
    "        input_words = input_words.translate(input_words.maketrans(\"\", \"\", string.punctuation)).split()\n",
    "        vectors = [word_embedding[i.lower()] if i.lower() in word_embedding.keys() else word_embedding['unk'] for i\n",
    "                   in input_words]\n",
    "\n",
    "        vectors = torch.tensor(vectors).view(len(vectors), 1, -1)\n",
    "        output = model(vectors)\n",
    "        predicted_label = torch.argmax(output)\n",
    "        correct += int(predicted_label == gold_label)\n",
    "        total += 1\n",
    "        # print(predicted_label, gold_label)\n",
    "    print(\"Validation completed for epoch {}\".format(epoch + 1))\n",
    "    print(\"Validation accuracy for epoch {}: {}\".format(epoch + 1, correct / total))\n",
    "    validation_accuracy = correct/total\n",
    "\n",
    "    if validation_accuracy < last_validation_accuracy and trainning_accuracy > last_train_accuracy:\n",
    "        stopping_condition=True\n",
    "        print(\"Training done to avoid overfitting!\")\n",
    "        print(\"Best validation accuracy is:\", last_validation_accuracy)\n",
    "    else:\n",
    "        last_validation_accuracy = validation_accuracy\n",
    "        last_train_accuracy = trainning_accuracy\n",
    "\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f49a5-286e-473d-8fb0-03cd0d57a8c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
